{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face ID project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def showImg(img, title = ''):\n",
    "    plt.figure(figsize = (10,10));\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def showGrayScaleImg(img, title = ''):\n",
    "    plt.figure(figsize = (10,10));\n",
    "    plt.title(title)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "all_contours = -1\n",
    "green = (0,255,0)\n",
    "thickness = 2\n",
    "\n",
    "new_img = cv2.UMat(cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "#####################################3\n",
    "\n",
    "image_template = []\n",
    "\n",
    "image_template.append(cv2.imread('img/eva.jpg')) \n",
    "image_template.append(cv2.imread('img/edgar.jpg'))\n",
    "#for i in range(len(image_template)):\n",
    " #   showImg(image_template[i])\n",
    "    \n",
    "####################################3\n",
    "\n",
    "def ORB_detector(new_image, image_template):\n",
    "    # Function that compares input image to template\n",
    "    # It then returns the number of ORB matches between them\n",
    "    \n",
    "    image1 = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #showImg(image1)\n",
    "    \n",
    "    # Create ORB detector with 1000 keypoints with a scaling pyramid factor of 1.2\n",
    "    orb = cv2.ORB_create(1000, 1.2)\n",
    "    \n",
    "    # Detect keypoints of original image\n",
    "    (kp1, des1) = orb.detectAndCompute(image1, None)\n",
    "\n",
    "    # Detect keypoints of rotated image\n",
    "    (kp2, des2) = orb.detectAndCompute(image_template, None)\n",
    "\n",
    "    # Create matcher     \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Do matching\n",
    "    matches = bf.match(des1,des2)\n",
    "\n",
    "    # Sort the matches based on distance.  Least distance\n",
    "    # is better\n",
    "    matches = sorted(matches, key=lambda val: val.distance)\n",
    "    \n",
    "    if len(matches) > 210:\n",
    "        matches_img = cv2.drawMatches(image1,kp1,image_template,kp2,matches[:20],None)\n",
    "        cv2.imwrite('orbMatches.jpg',matches_img)\n",
    "\n",
    "    return matches\n",
    "\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[465 255 364 364]]\n",
      "[[454 260 362 362]]\n",
      "[[453 264 361 361]]\n",
      "[[446 256 377 377]]\n",
      "[[449 258 376 376]]\n",
      "[[455 264 357 357]]\n",
      "[[452 255 374 374]]\n",
      "[[447 254 375 375]]\n",
      "[[443 252 382 382]]\n",
      "[[447 252 376 376]]\n",
      "[[449 256 370 370]]\n",
      "[[469 250 355 355]]\n",
      "[[494 269 313 313]]\n",
      "[[502 271 302 302]]\n",
      "[[517 279 302 302]]\n",
      "[[518 254 290 290]]\n",
      "[[475 253 297 297]]\n",
      "[[472 272 304 304]]\n",
      "[[474 255 307 307]]\n",
      "[[478 246 294 294]]\n",
      "[[470 220 303 303]]\n",
      "[[485 256 290 290]]\n",
      "[[487 249 298 298]]\n",
      "[[493 266 298 298]]\n",
      "[[470 297 266 266]]\n",
      "[[437 264 289 289]]\n",
      "[[434 247 291 291]]\n",
      "[[446 244 296 296]]\n",
      "[[460 236 302 302]]\n",
      "[[473 249 286 286]]\n",
      "[[474 246 286 286]]\n",
      "[[474 244 289 289]]\n",
      "[[468 235 299 299]]\n",
      "[[485 233 286 286]]\n",
      "[[493 241 286 286]]\n",
      "[[481 238 299 299]]\n",
      "[[482 238 299 299]]\n",
      "[[487 240 292 292]]\n",
      "[[510 229 284 284]]\n",
      "[[557 211 280 280]]\n",
      "[[570 170 288 288]]\n",
      "[[391 164 330 330]]\n",
      "[[152  53 373 373]\n",
      " [848 324 176 176]]\n",
      "[[703 241 175 175]]\n",
      "[[685 186 198 198]]\n",
      "[[626 252 199 199]]\n",
      "[[607 234 199 199]]\n",
      "[[574 259 186 186]]\n",
      "[[553 262 192 192]]\n",
      "[[547 259 187 187]]\n",
      "[[547 264 182 182]]\n",
      "[[549 266 185 185]]\n",
      "[[550 273 179 179]]\n",
      "[[549 276 175 175]]\n",
      "[[545 265 186 186]]\n",
      "[[538 250 202 202]]\n",
      "[[537 245 188 188]]\n",
      "[[520 245 195 195]]\n",
      "[[518 248 199 199]]\n",
      "[[520 257 197 197]]\n",
      "[[528 267 185 185]]\n",
      "[[513 223 197 197]]\n",
      "[[519 178 207 207]]\n",
      "[[575 224 194 194]]\n",
      "[[628 330 199 199]]\n",
      "[[829 428 202 202]]\n",
      "[[123  77 483 483]]\n",
      "[[202 199 406 406]]\n",
      "[[370 190 314 314]]\n",
      "[[384 160 317 317]]\n",
      "[[312 167 313 313]]\n",
      "[[ 307  197  320  320]\n",
      " [1096  420  170  170]]\n",
      "[[ 350  235  304  304]\n",
      " [1083  472  175  175]]\n",
      "[[482 223 289 289]]\n",
      "[[530 209 288 288]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[458 233 335 335]]\n",
      "[[465 249 332 332]]\n",
      "[[486 264 312 312]]\n",
      "[[491 262 313 313]]\n",
      "[[488 265 308 308]]\n",
      "[[493 264 313 313]]\n",
      "[[492 268 304 304]]\n",
      "[[491 266 308 308]]\n",
      "[[487 261 322 322]]\n",
      "[[498 259 311 311]]\n",
      "[[496 255 310 310]]\n",
      "[[493 264 301 301]]\n",
      "[[501 262 314 314]]\n",
      "[[497 259 327 327]]\n",
      "[[505 260 312 312]]\n",
      "[[505 258 328 328]]\n",
      "[[556 257 316 316]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[565 273 315 315]]\n",
      "[[508 269 320 320]]\n",
      "[[472 269 348 348]]\n",
      "[[488 282 315 315]]\n",
      "[[479 271 339 339]]\n",
      "[[472 263 334 334]]\n",
      "[[458 259 345 345]]\n",
      "[[483 261 333 333]]\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get webcam images\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    top_left_x = width // 3\n",
    "    top_left_y = (height // 2) + (height // 4)\n",
    "    bottom_right_x = (width // 3) * 2\n",
    "    bottom_right_y = (height // 2) - (height // 4)\n",
    "\n",
    "    faces = face_classifier.detectMultiScale(frame, 1.3, 5)\n",
    "    print(faces)\n",
    "    \n",
    "    people_values =[]\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h), (127,0,255), 2)\n",
    "    \n",
    "        magin = 30\n",
    "        top_left_x = x-magin\n",
    "        top_left_y = y-magin\n",
    "        bottom_right_x = x+w+magin\n",
    "        bottom_right_y = y+h+magin\n",
    "    \n",
    "\n",
    "        cropped = frame[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "  \n",
    "        # Repasa todas las caras \n",
    "        for i in range(len(image_template)):\n",
    "            matches = ORB_detector(cropped, image_template[i])\n",
    "            \n",
    "            people_values.append(matches)\n",
    "\n",
    "        threshold = 150\n",
    "\n",
    "        # If matches exceed our threshold then object has been detected\n",
    "        for i in range(len(image_template)):\n",
    "            \n",
    "            if len(people_values[i]) > threshold:\n",
    "                #frame = frame.copy()\n",
    "                if i == 0:\n",
    "                    text = \"Eva \"+str(len(people_values[i]))\n",
    "                    #cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "                    cv2.putText(frame,text,(int(top_left_x+w/2),top_left_y-20), cv2.FONT_HERSHEY_COMPLEX, 1 ,(127,0,255), 2) \n",
    "\n",
    "                elif i == 1:\n",
    "                    text = \"Edgar \"+str(len(people_values[i]))\n",
    "                    #cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "                    cv2.putText(frame,text,(int(top_left_x+w/2),top_left_y+10), cv2.FONT_HERSHEY_COMPLEX, 1 ,(127,0,255), 2) \n",
    "\n",
    "                \n",
    "                \n",
    "        # Flip frame orientation horizontally\n",
    "  #  frame = cv2.flip(frame,1)\n",
    "            \n",
    "    cv2.imshow('Object Detector using ORB', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
