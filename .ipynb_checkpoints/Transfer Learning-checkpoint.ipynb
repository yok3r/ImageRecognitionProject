{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "eva=[]\n",
    "for image_path in glob.glob(\"image_aumentation/Eva/*.jpg\"):\n",
    "    image = imageio.imread(image_path)\n",
    "    eva.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "edgar=[]\n",
    "for image_path in glob.glob(\"image_aumentation/Edgar/*.jpg\"):\n",
    "    image = imageio.imread(image_path)\n",
    "    edgar.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_res=[]\n",
    "width = 224\n",
    "height = 224\n",
    "for image in eva:\n",
    "    image_resized = cv2.resize(image,(width,height),interpolation = cv2.INTER_CUBIC)\n",
    "    eva_res.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_res=[]\n",
    "width = 224\n",
    "height = 224\n",
    "for image in edgar:\n",
    "    image_resized = cv2.resize(image,(width,height),interpolation = cv2.INTER_CUBIC)\n",
    "    edgar_res.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_eva=[]\n",
    "for i in range(len(eva_res)):\n",
    "    gray_eva= cv2.cvtColor(eva_res[i],cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.adaptiveThreshold(gray_eva, 255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,27,10)\n",
    "    color_eva= cv2.cvtColor(edges,cv2.COLOR_GRAY2RGB)\n",
    "    edited_eva.append(color_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_edgar=[]\n",
    "for i in range(len(eva_res)):\n",
    "    gray_eva= cv2.cvtColor(edgar_res[i],cv2.COLOR_BGR2RGB)\n",
    "    edges = cv2.adaptiveThreshold(gray_eva, 255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,27,10)\n",
    "    color_edgar= cv2.cvtColor(edges,cv2.COLOR_GRAY2RGB)\n",
    "    edited_edgar.append(color_edgar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-pocesat imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1f0f23b3c700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medited_eva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "edited_eva.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = np.array(edited_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar = np.asarray(edited_edgar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = eva.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147.20000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = total*0.8\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = np.split(eva,[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar = np.split(edgar,[147])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_train = eva[0]\n",
    "eva_test = eva[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_train = edgar[0]\n",
    "edgar_test = edgar[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_eva_train=np.zeros((147))\n",
    "label_eva_test=np.zeros((37))\n",
    "#We define that if we have a 0 is a Eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_edgar_train=np.ones((147))\n",
    "label_edgar_test=np.ones((37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 224, 224, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 224, 224, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgar_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.concatenate((eva_train,edgar_train))\n",
    "test_x=np.concatenate((eva_test,edgar_test))\n",
    "train_y=np.concatenate((label_eva_train,label_edgar_train))\n",
    "test_y=np.concatenate((label_eva_test,label_edgar_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "#ESTO NO DEBE DE ESTAR AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 16:23:09.808549 140029795669824 deprecation.py:506] From /home/eva/anaconda3/envs/akademyai/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "IMG_SHAPE = (image_size, image_size,3)\n",
    "#This is the size of the images in the input\n",
    "\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(350, activation='elu'),\n",
    "    #keras.layers.Flatten(data_format=None),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 16:23:18.384639 140029795669824 deprecation.py:323] From /home/eva/anaconda3/envs/akademyai/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# We need to compile the model before train it\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AQUI ES DONDE ENTRENAMOS EL MODELO DEFINIDO ANTERIORMENTE CON NUESTROS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "294/294 [==============================] - 34s 114ms/sample - loss: 0.6608 - acc: 0.6054\n",
      "Epoch 2/8\n",
      "294/294 [==============================] - 30s 103ms/sample - loss: 0.6192 - acc: 0.6395\n",
      "Epoch 3/8\n",
      "294/294 [==============================] - 26s 88ms/sample - loss: 0.5671 - acc: 0.6939\n",
      "Epoch 4/8\n",
      "294/294 [==============================] - 28s 95ms/sample - loss: 0.5493 - acc: 0.7313\n",
      "Epoch 5/8\n",
      "294/294 [==============================] - 27s 91ms/sample - loss: 0.5072 - acc: 0.7721\n",
      "Epoch 6/8\n",
      "294/294 [==============================] - 28s 94ms/sample - loss: 0.4972 - acc: 0.7585\n",
      "Epoch 7/8\n",
      "294/294 [==============================] - 27s 93ms/sample - loss: 0.4590 - acc: 0.8197\n",
      "Epoch 8/8\n",
      "294/294 [==============================] - 27s 92ms/sample - loss: 0.4352 - acc: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5afeb232b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 7s 95ms/sample - loss: 0.9283 - acc: 0.5000\n",
      "test accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9282755561777063\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10480145],\n",
       "       [0.21392503],\n",
       "       [0.16328302],\n",
       "       [0.12025914],\n",
       "       [0.04992551],\n",
       "       [0.05064276],\n",
       "       [0.04636964],\n",
       "       [0.04151812],\n",
       "       [0.13811001],\n",
       "       [0.13149562],\n",
       "       [0.09882107],\n",
       "       [0.08516836],\n",
       "       [0.07706714],\n",
       "       [0.09439242],\n",
       "       [0.0239799 ],\n",
       "       [0.13765174],\n",
       "       [0.15575829],\n",
       "       [0.21743938],\n",
       "       [0.53430015],\n",
       "       [0.07604858],\n",
       "       [0.1142084 ],\n",
       "       [0.08194533],\n",
       "       [0.19057503],\n",
       "       [0.07664981],\n",
       "       [0.13063145],\n",
       "       [0.13975638],\n",
       "       [0.19884652],\n",
       "       [0.13967165],\n",
       "       [0.04857606],\n",
       "       [0.09592026],\n",
       "       [0.04783106],\n",
       "       [0.09921175],\n",
       "       [0.22319335],\n",
       "       [0.04549947],\n",
       "       [0.04070854],\n",
       "       [0.15835312],\n",
       "       [0.18478724],\n",
       "       [0.02692813],\n",
       "       [0.15695155],\n",
       "       [0.21232074],\n",
       "       [0.30710852],\n",
       "       [0.16681972],\n",
       "       [0.07026404],\n",
       "       [0.4346702 ],\n",
       "       [0.22734854],\n",
       "       [0.18880674],\n",
       "       [0.13197988],\n",
       "       [0.21963361],\n",
       "       [0.2492562 ],\n",
       "       [0.08786106],\n",
       "       [0.10522282],\n",
       "       [0.1127902 ],\n",
       "       [0.09678507],\n",
       "       [0.20848304],\n",
       "       [0.14574921],\n",
       "       [0.14792377],\n",
       "       [0.4408933 ],\n",
       "       [0.32452202],\n",
       "       [0.2832576 ],\n",
       "       [0.05072573],\n",
       "       [0.32500204],\n",
       "       [0.144405  ],\n",
       "       [0.5012941 ],\n",
       "       [0.09560153],\n",
       "       [0.3079092 ],\n",
       "       [0.321401  ],\n",
       "       [0.3489528 ],\n",
       "       [0.3666494 ],\n",
       "       [0.11108556],\n",
       "       [0.08999741],\n",
       "       [0.168403  ],\n",
       "       [0.24838775],\n",
       "       [0.25348556],\n",
       "       [0.20167387]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_test shape: ', test_x.shape)\n",
    "x_test_plt = np.squeeze(test_x)\n",
    "print('x_test_plt shape: ', x_test_plt.shape)\n",
    "print('predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #see results\n",
    "i = 1\n",
    "plt.imshow(x_test_plt[i])\n",
    "print('Prediction: ' , np.where(predictions[i]<=0.5,'Eva','Edgar'))\n",
    "print('With an accuracy of:', np.round(score[1]*100,2), '%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE THE MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la Eva es 0 i Edgar es 1 fem que si es mes gran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REAL TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "# Load our image template, this is our reference image\n",
    "image_template = cv2.imread('eva2.jpeg', 0) \n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get webcam images\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    img = np.resize(frame, (224,224,3))\n",
    "    im2arr = np.array(img)\n",
    "    im2arr1 = im2arr.reshape(1,224,224,3)\n",
    "    predictions = model.predict(im2arr1)\n",
    "    if predictions < 0.4:\n",
    "        text = \"EVA\"\n",
    "    if predictions > 0.6:\n",
    "        text = \"EDGAR\"\n",
    "    else:\n",
    "        text = \" \"\n",
    "    \n",
    "    cv2.putText(frame,text,(30,70), cv2.FONT_HERSHEY_COMPLEX, 2 ,(255,255,255), 6)\n",
    "    #cv2.putText(frame,predictions[0][0],(150,150), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "    cv2.imshow('Object Detector using ORB', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
